// app/studio/page.tsx
"use client";

import { useEffect, useRef, useState } from "react";
import {
  FaceLandmarker,
  FilesetResolver,
  type FaceLandmarkerResult,
} from "@mediapipe/tasks-vision";

type Capture = {
  url: string;
  createdAt: number;
};

type EyebrowStyle = {
  id: string;
  name: string;
  color: string;   // rgba ë˜ëŠ” hex
  thickness: number; // ë‘ê»˜(1 ~ 3 ì •ë„)
  offsetY: number;   // yì¶• ì˜¤í”„ì…‹ (ìŒìˆ˜ë©´ ì•½ê°„ ìœ„ë¡œ ì˜¬ë¼ê°)
};

export default function StudioPage() {
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);

  const landmarkerRef = useRef<FaceLandmarker | null>(null);
  const lastVideoTimeRef = useRef<number>(-1);

  const [cameraReady, setCameraReady] = useState(false);
  const [landmarkerReady, setLandmarkerReady] = useState(false);
  const [captures, setCaptures] = useState<Capture[]>([]);
  const [errorMsg, setErrorMsg] = useState<string | null>(null);

  // ğŸ‘‰ ëˆˆì¹ í…œí”Œë¦¿ ëª©ë¡
  const [styles] = useState<EyebrowStyle[]>([
    {
      id: "natural",
      name: "ë‚´ì¶”ëŸ´",
      color: "rgba(60, 40, 30, 0.75)",
      thickness: 1.0,
      offsetY: 0.0,
    },
    {
      id: "soft-flat",
      name: "ì†Œí”„íŠ¸ ì¼ì",
      color: "rgba(45, 35, 28, 0.82)",
      thickness: 1.3,
      offsetY: -0.003,
    },
    {
      id: "flat",
      name: "ì„ ëª… ì¼ì",
      color: "rgba(30, 22, 18, 0.88)",
      thickness: 1.6,
      offsetY: -0.006,
    },
    {
      id: "arch",
      name: "ì•„ì¹˜",
      color: "rgba(55, 35, 25, 0.85)",
      thickness: 1.4,
      offsetY: -0.01,
    },
    {
      id: "strong-arch",
      name: "ê°•í•œ ì•„ì¹˜",
      color: "rgba(25, 18, 14, 0.9)",
      thickness: 1.9,
      offsetY: -0.014,
    },
  ]);
  const [selectedStyleId, setSelectedStyleId] = useState<string>("natural");

  // 1) ì¹´ë©”ë¼ ì¼œê¸°
  useEffect(() => {
    let stream: MediaStream | null = null;

    const startCamera = async () => {
      try {
        setErrorMsg(null);
        stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user" },
          audio: false,
        });

        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => {
            videoRef.current?.play();
            setCameraReady(true);
          };
        }
      } catch (e) {
        console.error(e);
        setErrorMsg("ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.");
      }
    };

    startCamera();

    return () => {
      if (stream) {
        stream.getTracks().forEach((t) => t.stop());
      }
    };
  }, []);

  // 2) MediaPipe Face Landmarker ì´ˆê¸°í™”
  useEffect(() => {
    const initLandmarker = async () => {
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );

        const landmarker = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath:
              "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          },
          numFaces: 1,
          runningMode: "VIDEO",
        });

        landmarkerRef.current = landmarker;
        setLandmarkerReady(true);
      } catch (e) {
        console.error(e);
        setErrorMsg("ì–¼êµ´ ì¸ì‹ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
      }
    };

    initLandmarker();
  }, []);

  // 3) ë¹„ë””ì˜¤ â†’ ìº”ë²„ìŠ¤ ë Œë” + ëˆˆì¹ ì˜¤ë²„ë ˆì´
  useEffect(() => {
    if (!cameraReady || !videoRef.current || !canvasRef.current) return;

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    let frameId: number;

    const render = async () => {
      frameId = requestAnimationFrame(render);

      if (video.readyState < 2) return;

      const vw = video.videoWidth;
      const vh = video.videoHeight;
      if (!vw || !vh) return;

      if (canvas.width !== vw || canvas.height !== vh) {
        canvas.width = vw;
        canvas.height = vh;
      }

      // 1. ì›ë³¸ í”„ë ˆì„
      ctx.drawImage(video, 0, 0, vw, vh);

      // 2. ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ë¡ 
      if (!landmarkerRef.current || !landmarkerReady) return;

      const nowInMs = performance.now();
      if (lastVideoTimeRef.current === nowInMs) return;
      lastVideoTimeRef.current = nowInMs;

      const result: FaceLandmarkerResult =
        landmarkerRef.current.detectForVideo(video, nowInMs);

      if (!result.faceLandmarks || result.faceLandmarks.length === 0) return;

      const landmarks = result.faceLandmarks[0];
      const style =
        styles.find((s) => s.id === selectedStyleId) ?? styles[0];

      // 3. í˜„ì¬ ì„ íƒëœ ìŠ¤íƒ€ì¼ë¡œ ëˆˆì¹ ê·¸ë¦¬ê¸°
      drawEyebrows(ctx, landmarks, style);
    };

    render();

    return () => cancelAnimationFrame(frameId);
  }, [cameraReady, landmarkerReady, selectedStyleId, styles]);

  // 4) ìº¡ì²˜
  const handleCapture = () => {
    if (!canvasRef.current) return;
    const url = canvasRef.current.toDataURL("image/png");
    setCaptures((prev) => [{ url, createdAt: Date.now() }, ...prev]);
  };

  return (
    <main className="min-h-screen bg-slate-950 text-white flex flex-col items-center py-8 px-4">
      <h1 className="text-xl md:text-2xl font-semibold mb-1">
        ë°˜ì˜êµ¬ ëˆˆì¹ ì‹œë®¬ë ˆì´í„° â€“ ìŠ¤íŠœë””ì˜¤ MVP
      </h1>
      <p className="text-sm text-white/65 mb-4">
        ì‹¤ì‹œê°„ ì¹´ë©”ë¼ + í…œí”Œë¦¿ ì„ íƒìœ¼ë¡œ ë°”ë¡œ ìŠ¤íƒ€ì¼ ë¹„êµ.
      </p>

      {errorMsg && (
        <div className="mb-3 rounded-md border border-red-500/60 bg-red-500/10 px-3 py-2 text-sm text-red-100">
          {errorMsg}
        </div>
      )}

      <video ref={videoRef} className="hidden" playsInline />

      <div className="w-full max-w-md aspect-[3/4] rounded-xl overflow-hidden border border-white/15 bg-black flex items-center justify-center">
        <canvas ref={canvasRef} className="w-full h-full" />
      </div>

      {/* ğŸ‘‰ í…œí”Œë¦¿ ì„ íƒ íŒ¨ë„ */}
      <section className="mt-4 w-full max-w-md">
        <h2 className="text-xs font-medium text-white/60 mb-2">
          ëˆˆì¹ í…œí”Œë¦¿ ì„ íƒ
        </h2>
        <div className="flex flex-wrap gap-2">
          {styles.map((style) => (
            <button
              key={style.id}
              onClick={() => setSelectedStyleId(style.id)}
              className={`px-3 py-1.5 rounded-full text-xs border transition
              ${
                selectedStyleId === style.id
                  ? "border-emerald-400 bg-emerald-500/10 text-emerald-200"
                  : "border-white/20 bg-white/5 text-white/80"
              }`}
            >
              {style.name}
            </button>
          ))}
        </div>
      </section>

      <button
        onClick={handleCapture}
        disabled={!cameraReady}
        className="mt-4 px-4 py-2 rounded-md bg-emerald-500 text-sm font-medium disabled:bg-gray-600"
      >
        {cameraReady ? "í˜„ì¬ í™”ë©´ ìº¡ì²˜" : "ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘..."}
      </button>

      <p className="mt-2 text-xs text-white/50">
        ì–¼êµ´ ì¸ì‹ ëª¨ë¸: {landmarkerReady ? "ë¡œë“œ ì™„ë£Œ" : "ë¡œë”© ì¤‘..."}
      </p>

      {captures.length > 0 && (
        <section className="mt-6 w-full max-w-md">
          <h2 className="text-sm font-medium mb-2 text-white/80">
            ìº¡ì²˜ ì´ë¯¸ì§€
          </h2>
          <div className="grid grid-cols-3 gap-2">
            {captures.map((c) => (
              <div
                key={c.createdAt}
                className="border border-white/10 rounded-md overflow-hidden"
              >
                <img src={c.url} alt="capture" className="w-full h-auto" />
              </div>
            ))}
          </div>
        </section>
      )}
    </main>
  );
}

/** ===== ëˆˆì¹ ê·¸ë¦¬ê¸° ìœ í‹¸ ===== */

// ëŒ€ëµì ì¸ MediaPipe FaceMesh ì¸ë±ìŠ¤
const LEFT_EYEBROW = [52, 65, 55, 107, 66, 105, 63, 70, 156];
const RIGHT_EYEBROW = [282, 295, 285, 336, 296, 334, 293, 300, 383];

function drawEyebrows(
  ctx: CanvasRenderingContext2D,
  landmarks: { x: number; y: number; z?: number }[],
  style: EyebrowStyle
) {
  drawOneSide(ctx, landmarks, LEFT_EYEBROW, style);
  drawOneSide(ctx, landmarks, RIGHT_EYEBROW, style);
}

function drawOneSide(
  ctx: CanvasRenderingContext2D,
  landmarks: { x: number; y: number }[],
  indices: number[],
  style: EyebrowStyle
) {
  if (!indices.length) return;

  ctx.fillStyle = style.color;

  // thicknessë¥¼ ì´ìš©í•´ ì•½ê°„ ë„“ê²Œ ë®ê¸° ìœ„í•´ shadow íš¨ê³¼ ë¹„ìŠ·í•˜ê²Œ ì‚¬ìš©
  ctx.save();
  ctx.filter = "blur(0.6px)";

  ctx.beginPath();

  indices.forEach((i, idx) => {
    const lm = landmarks[i];
    if (!lm) return;

    const x = lm.x * ctx.canvas.width;
    const y =
      (lm.y + style.offsetY) * ctx.canvas.height; // offsetYë¡œ ì‚´ì§ ìœ„/ì•„ë˜ ì¡°ì •

    if (idx === 0) ctx.moveTo(x, y);
    else ctx.lineTo(x, y);
  });

  ctx.closePath();
  ctx.fill();

  // thickness ê°’ìœ¼ë¡œ í•œ ë²ˆ ë” ë®ì–´ì„œ ë‘ê»˜ ì¡°ì ˆ
  if (style.thickness > 1) {
    const scale = 1 + (style.thickness - 1) * 0.06; // ê³¼í•˜ì§€ ì•Šê²Œ
    ctx.beginPath();
    indices.forEach((i, idx) => {
      const lm = landmarks[i];
      if (!lm) return;
      const cx = 0.5 * ctx.canvas.width;
      const cy = 0.4 * ctx.canvas.height;

      const baseX = lm.x * ctx.canvas.width;
      const baseY = (lm.y + style.offsetY) * ctx.canvas.height;

      const x = cx + (baseX - cx) * scale;
      const y = cy + (baseY - cy) * scale;

      if (idx === 0) ctx.moveTo(x, y);
      else ctx.lineTo(x, y);
    });
    ctx.closePath();
    ctx.fill();
  }

  ctx.restore();
}
